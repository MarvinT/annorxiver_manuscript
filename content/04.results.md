## Results

### Comparing bioRxiv to other corpora

#### bioRxiv Metadata Statistics

The preprint landscape is rapidly changing, and the number of bioRxiv preprints in our data download (71,118) was nearly double that of a recent study that reported on a snapshot with 37,648 preprints [@doi:10.7554/eLife.45133].
Because the rate of change is rapid, we first analyzed category data and compared our results with previous findings.
As in previous reports [@doi:10.7554/eLife.45133], neuroscience remains the most common category of preprint followed by bioinformatics (Supplemental Figure {@fig:biorxiv_categories}).
Microbiology, which was fifth in the most recent report [@doi:10.7554/eLife.45133], has now surpassed evolutionary biology and genomics to move into third.
When authors upload their preprints, they select from three result category types: new results, confirmatory results or contradictory results.
We found that nearly all preprints (97.5%) were categorized as new results, which is consistent with reports on a smaller set [@doi:10.1001/jama.2017.21168].
Taken together, the results suggest that while bioRxiv has experienced dramatic growth, the way in which it is being used appears to have remained consistent in recent years.

#### Global Comparison of bioRxiv and PubMed Central

| Metric                | bioRxiv     | PMC           | NYTAC         |
|-----------------------|-------------|---------------|---------------|
| document count             | 71,118      | 1,977,647     | 1,855,658     |
| sentence count             | 22,195,739  | 480,489,811   | 72,171,037    |
| token count                | 420,969,930 | 8,597,101,167 | 1,218,673,384 |
| stopword count            | 158,429,441 | 3,153,077,263 | 559,391,073   |
| avg. document length        | 312.10      | 242.96        | 38.89         |
| avg. sentence length        | 22.71       | 21.46         | 19.89         |
| negatives                  | 1,148,382   | 24,928,801    | 7,272,401     |
| coordinating conjunctions  | 14,295,736  | 307,082,313   | 38,730,053    |
| coordinating conjunctions% | 3.40%       | 3.57%         | 3.18%         |
| pronouns                   | 4,604,432   | 74,994,125    | 46,712,553    |
| pronouns%                  | 1.09%        | 0.87%         | 3.83%         |
| passives                   | 15,012,441  | 342,407,363   | 19,472,053    |
| passive%                   | 3.57%       | 3.98%         | 1.60%         |

Table: Generated corpora statistics for all corpus used in this project. {#tbl:corpora_stats}

![
A. This barplot represents the KL divergence between bioRxiv, Pubmed Central and the reference corpus.
The y-axis is the KL divergence metric where lower values indicates similar distributions and vice versa for higher values.
The x-axis represents the number of highly occuring tokens used to calculate the KL divergence.
B. This is a point range plot of the odds ratio with respect to bioRxiv.
Values greater than one indicate a high association with bioRxiv whereas values less than one indicate high association with PubMed Central.
The dotted line provides a breaking point between both categories.
C. This is a bar chart of token frequency appearing in bioRxiv and PMC respectively.
D. This is a point range plot of the odds ratio with respect to preprints.
Values greater than one indicate a high association with preprints while values less than one indicate a high association with published articles.
The dotted line provides a breaking point between both categories.
E. This is a barchart of token frequency appearing in preprints and published versions of preprints respectively.
](https://raw.githubusercontent.com/greenelab/annorxiver/472d9b2abd42aecff339fe21c8378f9a556b80d8/figure_generation/output/figure_one_panels.svg){#fig:corpora_comparison_panels, width="100%"}

The linguistic style of the bioRxiv corpus differs from the PMC corpus.
We compared and contrasted preprints in bioRxiv, published manuscripts in PMC and newspaper articles from the New York Times (NYTAC) against eachother.
We refer to NYTAC as our reference corpus for the following analysis.
We found that bioRxiv is more similar to PMC than to the reference in terms of token frequencies and corpora statistics (Figure {@fig:corpora_comparison_panels}A and Table {@tbl:corpora_stats}).
When comparing bioRxiv and PMC to the reference, topic associated and measurement related tokens appear highly enriched (Supplemental Figures {@fig:biorxiv_v_reference} and {@fig:pmc_v_reference}).
Furthermore, we found that tokens such as "neuron", "genome", "RNA" and "network" had a high odds ratio, while tokens such as "patient", "health", $\pm$, and "ml" to have a low odds ratio when comparing bioRxiv to PMC (Figure {@fig:corpora_comparison_panels}B and {@fig:corpora_comparison_panels}C).
This separation of tokens suggests that articles focused on clinical trials and patient research are more prevalent in PMC than to bioRxiv.
This separation also suggests that bioRxiv has a predominance of preprints focused on neuroscience and bioinformatic topics.
In regard to writing, citation styles diversify from the familiar "et al." form as preprints transition through the publication process.
Additionally, published articles have an increase of typesetting ($\pm$) and measurement symbols ("ml", "age") compared to preprints.

A preprint's linguistic style can change once a preprint has undergone the revision process prior to being published.
We quantified this linguistic difference by calculating the odds ratio of tokens appearing in the union of bioRxiv preprints and their published counterparts within PMC.
Tokens with an odds ratio greater than one are mainly centered on paper/figure references and research specific terms (Figure {@fig:corpora_comparison_panels}D and {@fig:corpora_comparison_panels}E).
Tokens with an odds ratio of less than one are focused on data availability, and research measurements such as number of cases and controls or significance testing (Figure {@fig:corpora_comparison_panels}D and {@fig:corpora_comparison_panels}E).
This enrichment suggests that a key piece in the publication process is verifying that essential parts of research (e.g. data availability, specific measurements) are obvious to future readers within the scientific community.

### Topic Analysis of bioRxiv's Principal Components

![
A. The scatter plot at the top right (A) is a visualization of documents being plotted along the PC directions.
Article categories were hand-picked based on the concepts captured by each PC.
B. The word cloud depicts the cosine similarity score between tokens and the second PC.
Tokens in orange are most similar to a PC's positive direction while tokens in blue are most similar to a PC's negative direction.
The size of each token indicates the magnitude of the similarity score.
C. The word cloud depicts the cosine similarity score between tokens and the first PC.
Tokens in orange are most similar to a PC's positive direction while tokens in blue are most similar to a PC's negative direction.
The size of each token indicates the magnitude of the similarity score.
D. This is box plot shows preprints in each article category projected along the PC1 direction.
Negative values indicate molecular biology concepts, while positive values indicate quantitative biology concepts.
E. This is box plot shows preprints in each article category projected along the PC2 direction.
Negative values indicate neuroscience concepts, while positive values indicate bioinformatic concepts.
](https://raw.githubusercontent.com/greenelab/annorxiver/472d9b2abd42aecff339fe21c8378f9a556b80d8/figure_generation/output/figure_two_panels.svg){#fig:topic_analysis_panels, width="100%"}

We explored the primary differences between the full text of bioRxiv preprints by performing principal components analysis on generated document embeddings.
We visualized the correspondence between tokens and the loadings for each principal component (Figure {@fig:topic_analysis_panels}).
We also visualized documents projected on selected principal components (Figure {@fig:topic_analysis_panels}A).
The first principal component separates bioRxiv preprints that encompass molecular biology results with preprints that contain quantitative biology results (Figure {@fig:topic_analysis_panels}B).
This highlights the bisection of biomedical research where majority of results can be categorized under the molecular biology category or the quantitative biology category.
Furthermore, this bisecting trend is evident across individual preprint categories as most categories lie on either side of the first principal component (Figure {@fig:topic_analysis_panels}D).
As with the first principal component we also provide example preprints from the systems biology category to reinforce this concept (Supplemental Table {@tbl:five_pc1_table}).

The second principal component represents the concept of neuroscience vs bioinformatics (Figure {@fig:topic_analysis_panels}C).
This principal component suggests that the bulk of preprints within bioRxiv are largely focused around neuroscience and bioinformatic concepts.
This split is evident in Figure {@fig:topic_analysis_panels}E as enriched categories along this principal component are quite related to neuroscience (negative end) or bioinformatics (positive end).
We provide example preprints from the systems biology category to reinforce this concept (Supplemental Table {@tbl:five_pc2_table}).
More principal component word clouds can be found on our journal recommender website and within our online repository (see Software and Data Availability).

### Identifying preprints that were not linked with their corresponding publications

![
A. This violin plot shows the distribution of distances between the preprint-corresponding published version category and the preprint-randomly sampled articles category.
B. This bar chart depicts the fraction of true positives over the total number of pairs in each bin.
Each bin contains a total of 200 annotated pairs and is based on the percentiles of the preprint-published distribution.
C. This line plot shows the publication rate of preprints since bioRxiv first started.
The x-axis represents months since bioRxiv started and the y-axis represents the proportion of preprints published.
The light blue line represents the publication rate estimated by Abdill et al. [@doi:10.7554/eLife.45133].
The dark blue line represents the updated publication rate without missing links added while the dark green line is the updated publication rate with missing links added.
The horizontal lines represent the overall proportion of preprints that are published.
](https://raw.githubusercontent.com/greenelab/annorxiver/472d9b2abd42aecff339fe21c8378f9a556b80d8/figure_generation/output/figure_three_panels.svg){#fig:preprint_links_panels, width="100%"}

Many journals require that authors update preprints with links to the published version of their article.
This is accomplished in two ways: _bioRxiv_ may detect the link and automatically add it or authors may notify _bioRxiv_ that their preprint was published.
Sproadically, there are cases where _bioRxiv_ may miss detecting a link or authors may forget to notiy _bioRxiv_ of their recent publcation.
These missing links can make it more difficult to identify the latest version of scientific manuscripts and estimate the fraction of articles that are eventually published [@doi:10.7554/eLife.45133].
We used distance in the document space to identify preprints without an annotated publication but contained very similar content to published articles.
We found that distances between preprints and their corresponding published versions were lower than preprints paired with a random article published in the same journal (Figure {@fig:preprint_links_panels}A).
This observation suggests that pairs with low embedding distances could be considered a true match, so we separated articles into quantiles based on the distribution of distances between true preprint-publication pairs.
We curated 50 potential preprint-publication pairs from each of four quantiles and achieved a high inter-rater reliability of 91.7% (Cohen's Kappa [@doi:10.1177/001316446002000104]) for this task.
Out of these two hundred pairs we found that approximately 98% of pairs with an embedding distance in the 0-25th and 25th-50th percentile bins were true matches (Figure {@fig:preprint_links_panels}B).
These two bins contained 1,720 preprint-article pairs, suggesting that many preprints have been published but not previously connected with their published versions.

We overlaid these new annotations onto existing annotations to reassess the overall preprint publication rate reported by Abdill et al. [@doi:10.7554/eLife.45133].
Our filtering criteria were intentionally stringent, so the increased estimate of publication rate amounts to a few percent (Figure {@fig:preprint_links_panels}C).
Many of these missed annotations were for preprints posted in the 2017-2018 interval.
Compared to preprints published in 2019 and later, the preprints posted in 2017-2018 are old enough to have a high chance of being published; however, it is interesting that the rate for older preprints was not observed to be higher.

### Factors that affect the time between preprinting and publication

![
A.This squarebin plot depicts the amount of time it takes a preprint to be published against the distances of a preprint's first version and its corresponding published version.
The x-axis represents the Euclidean distance between document representations, while the y-axis represents the number of days elapsed between a preprint posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each square-bin in this plot where more dense regions have a brighter color compared to their counterparts.
B.This squarebin plot depicts the amount of time it takes a preprint to be published against the number of versions posted for a specific preprint.
The x-axis represents the number of different versions a preprint has on bioRxiv, while the y-axis represents the number of days elapsed between a preprint posted on bioRxiv and the time a preprint is published.
The color bar on the right represents the density of each square-bin in this plot where more dense regions have a brighter color compared to their counterparts.
C.This bargraph depicts the amount of time it takes to get half of the total number of preprints published.
The x-axis reprints days until 50% of preprints are published and the y-axis reprints the different preprint categories.
](https://raw.githubusercontent.com/greenelab/annorxiver/472d9b2abd42aecff339fe21c8378f9a556b80d8/figure_generation/output/figure_four_panels.svg){#fig:publication_delay_panels, width="100%"}

Preprints undergo multiple review checkpoints before they are published within a journal [@doi:10.1002/nop2.51].
Oftentimes these checkpoints may result in rejection or revisions requested by a reviewer [@doi:10.1002/nop2.51].
These negative outcomes result in authors may having to drastically edit their preprint, which greatly impedes a preprint reaching a published endpoint.
We sought to quantify the extent to which preprints are stalled when faced with a setback from the peer-review process.
On average preprints are delayed approximately 16 days for every distance unit change (Figure {@fig:publication_delay_panels}A).
We found that the average distance between two preprints' in the bioinformatics category was 5.068, which suggests that a single distance unit represents a fifth of a preprint's total text being changed.
Sometimes preprints have to undergo drastic revisions that result in a new version being created.
We found that on average it takes 51 days for authors to construct a new version of a preprint (Figure {@fig:publication_delay_panels}B).
Both the document distance trend and the version number trend confirm that the larger the revision the longer it takes for a preprint to be published.

Preprints in certain categories take less time to publish than others.
we sought to quantify the time each category takes to publish half their total number of preprints.
Every preprint category takes at least 124 days to publish half of their respective preprints (Figure {@fig:publication_delay_panels}C).
Categories that took the least amount of time were microbiology and zoology, while scientific communication and education took the most time (Figure {@fig:publication_delay_panels}C).
Overall, this suggests that preprints in the microbiology and zoology categories may face less peer-review setbacks compared to other categories.

### Recommending Journals Based on Preprint Representation

We sought to identify journals that might publish a preprint based on the text of a paper.
We trained two different classifiers to predict the journal endpoints for already published papers.
One classifier uses the nearest journal centroids, which attempts to capture the topic area of a journal.
The other classifier aims to be more granular and recommends journals based on close proximity of individual papers.
Both classifiers achieved a substantial increase over the random baseline; however, our predictors are not perfect (Supplemental Figure {@fig:knn_auc}).
This is expected as our dataset contains 2516 different journals where some journals publish papers that cover very specific topic while others publish papers that have a broad set of covered topics.
Our journal centroid classifier performed better than the nearest paper classifier on the held out test set (Supplemental Figure {@fig:knn_auc}).
Overall, our software provides a starting point for authors to use the text of their preprints to identify potentially suitable publication venues.

![
Here is the workflow of the journal recommender web-app.
Starting with the homescreen users can paste in a _bioRxiv_ or _medRxiv_ DOI, which sends a request to biorxiv or medrxiv (A).
Next our app preprocesses the preprint and returns a listing of the top ten most similar papers (B) and the top ten closest journals to the query (C).
Following the listing, our app manually plots the preprint query onto the Pubmed Central Landscape (D).
Lastly, users can click on a square within the landscape, which will show bin statistics as well as associated word-odd ratios (E).
](images/journal_recommender_workflow.png){#fig:journal_rec_workflow, width="100%"}

We constructed an online app that provides users with journal suggestions based on their preprint content.
Users supply DOIs from _bioRxiv_ or _medRxiv_.
The application then downloads the article, converts the PDF to text, calculates a document embedding score, and returns the ten papers and journals with the most similar representations in the embedding space.
It also embeds the document into the overall PMC landscape for visualization and allows the user to examine principal components and term enrichment for each bin within the landscape (Figure {@fig:journal_rec_workflow}).
